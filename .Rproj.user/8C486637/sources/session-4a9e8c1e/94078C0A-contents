---
title: "home_work"
subtitle: "DEAD|LINE"
author: "Zarva_I"
date: "2024-09-17"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---
##START
```{r setup, include=FALSE, error = TRUE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages(c("bayesplot", "bayestestR")) #установил пакет через команду)
library(tidyverse)
library(flextable)
library(DescTools)
library(psych)
library(ggcorrplot)
library(ggpubr)
library(readxl)
library(readr)

```
## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

##Domashka

citation("ggplot2")
.libPaths()
library()
source("https://bioconductor.org/biocLite.R")

###Bioconductor
```{r}
if (!require("BiocManager", quietly = TRUE))  #установил Bioconductor
  install.packages("BiocManager")

BiocManager::install("BiocVersion")
```

###dplyr
```{r}
#mutate() — изменяет переменные, добавляет новые;
#select() — выбирает переменные;
#filter() — фильтрует объекты по условиям;
#summarise() — вычисляет сводные статистики;
#arrange() — сортирует по переменным;
#group_by() — группирует по значениям переменных;
#*_join() — группа глаголов для склеивания двух таблиц по ключу.

#Пакет позволяет:
#Поворачивать данные, то есть, преобразовывать их в длинный и широкий форматы: #pivot_longer(), pivot_wider();
#Разворачивать данные из вложенных списков в простые таблицы: unnest_longer(), unnest_wider();
#Наоборот, делать из таблиц вложенные переменные: nest(), unnest();
#Разделять и объединять столбцы по разделителю строк: separate(), unite();
#Заполнять отсутствующие значения определёнными значениями или удалять их: complete(), drop_na(), fill(), replace_na().
```

###readr, readxl, haven
```{r}
#Три основных пакета, которые помогают читать данные.

#readr предназначен для чтения самых распространённых форматов данных: *.csv, *.txt, *.tsv;
#redxl помогает читать файлы *.xlsx или, иными словами, всё, что пересылается в формате Excel;
#haven читает форматы *.sas7bdat, *.sap, *.dta, *.sav, *.por, то есть данные из SAS.
```

###purrr
```{r}
#Этот пакет может поначалу казаться сложным для понимания, однако на самом деле он просто расширяет функционал уже известного семейства функций *apply().
#Функция map() и её расширения позволяют итерироваться по элементам векторов или списков самыми разными способами
```

###tibble
```{r}
#В базовом R уже есть data.frame, однако tibble позволяет создавать гораздо более приятные для работы таблицы данных.

#В отличие от data.frame он не приводит строки к факторам автоматически. Это нужно сделать самостоятельно, однако таким образом мы всегда в точности знаем, что находится в каждой переменной датафрейма;
#Имена переменных остаются такими же, какими были. Например, в переменной с названием "variable name" пробел не будет заменён на точку, вместо этого имя будет окружено апострофами (обычно находятся на букве "ё"), что сохраняет ожидания от названий;
#tibble оценивает переменные лениво. По существу, это значит, что при создании мы можем объявлять одну переменную на основе другой (но эта другая должна быть указана первой).
```

###ggplot2 и ggpubr
```{r}
#Для визуализации данных существует сразу два пакета: базовый ggplot, содержащий в себе почти всю необходимую для создания графики функциональность.
#Дополнительные интересные особенности вроде автоматического расчёта и добавления на график p-value, реализованы в пакете ggpubr.
```

###flextable
```{r}
#Необходимо ещё и напечатать эти таблицы в виде, пригодном для восприятия коллегами без лишних проблем. Именно для этого нужен пакет flextable
```

###stringr
```{r}
#Очень часто в данных есть строковые переменные, в которых записана некая текстовая информация, важная нам для исследования. Например, в одной ячейке записаны все возможные названия препарата, и стоит задача взять только тех участников исследования, у которых название препарата содержит подстроку "циклин".
```

###lubridate
```{r}
#Помимо строковых данных часто встречаются и даты. С ними нельзя работать как с факторами, строками или, тем более, числами. Для этого существует специальная библиотека, которая может даже вычислить разницу между двумя датами с учётом високосных годов. 
```

###DescTools, psych
```{r}
#Существуют пакеты, в которых собраны статистические функции, позволяющие чуть ли не в одну строку подготовить базовый статистический отчёт.
#В DescTools мы найдём полезные функции для статистических тестов и доверительных интервалов, а в psych функции для корреляционных матриц и расчёта сразу группы статистик.
```

###read.*
```{r}
#Выше мы видим пример файла csv с разделителем-запятой. Обсудим конкретно, какими функциями читается каждый формат:

#read.csv() читает csv с запятой в качестве разделителя;
#read.csv2() читает csv с точкой с запятой в качестве разделителя (кстати, этот же формат отлично читает Excel, сразу разбивая его на столбцы);
#read.tsv() читает csv со знаком табуляции в качестве разделителя (часто этот формат сохраняют в файле с расширением .txt).
#Однако, в каждой функции при этом можно указать параметры sep, quote, dec, которые, соответственно, устанавливают знаки: разделителя, кавычек, десятичного разделителя. 
```

###write.*
```{r}
#write.csv(), write.csv2() печатают датафрейм в файлы csv с соответствующими разделителями, но их использование (особенно на Windows) может приводить к забавной вещи — поломке кодировки, когда символы в Excel не читаются человеком. Как решить эту проблему, мы узнаем в следующих шагах.
```

```{r}
read_tsv("data/raw/data_tsv.tsv", skip = 0, n_max = 10, col_names = TRUE)
```

###iris
```{r}
library(datasets)
data(iris)
summary(iris)
```
```{r}

#write_csv(data, "data/raw/data_csv.csv")

#write_excel_csv(data, "data/raw/data_csv.csv")

#write_csv2(data, "data/raw/data_csv2.csv")

#write_excel_csv2(data, "data/raw/data_csv2.csv")

#Ничего не работает...
```

###read_excel
```{r}
read_excel("data/raw/data_excel.xlsx", sheet = "data_csv2")
```

###xlsx::write.xlsx()

```{r}
#Существует несколько пакетов, позволяющих записывать данные в книги Excel: xlsx, openxlsx, writexl. Однако, здесь мы будем использовать openxlsx, поскольку он не требует установки Java и наиболее просто устанавливается почти на всех компьютерах.

#write.xlsx(data, "data_excel.xlsx", colNames = TRUE)

#Вот и всё. У нас появляется файл Excel с записанными данными. Перейдём к бонусу для тех, у кого установлен Java.

#openxlsx::write.xlsx(), openxlsx::write.xlsx2()

#Прежде всего отметим, что дублирующая функция с цифрой 2 используется преимущественно для того, чтобы быстро записывать крайне большие датафреймы (более, чем 100 тысяч ячеек).

#write.xlsx(data, "data_excel.xlsx", sheetName = "data", col.names = TRUE, row.names = TRUE, append = FALSE)

#Функция создаёт книгу Excel, а в ней лист с соответствующим именем. Аргументы col.names и row.names говорят, нужно ли записывать в файл имена столбцов и имена строк соответственно. Аргумент append нужен для того, чтобы...

#write.xlsx(data, "data_excel.xlsx", sheetName = "data_2", col.names = TRUE, row.names = TRUE, append = TRUE)

#...добавлять новые листы к уже существующей книге. 

#haven::read_spss(), haven::read_sas()

#Очень редко, но приходится читать данные, которые выгружены напрямую из SPSS или SAS.

#haven::write_sav() 

#Точно так же можно записать данные, чтобы наш предполагаемый коллега мог загрузить их в SPSS.

```


###mean()
```{r}
mean(c(20, 68, 45, 76, 41, 36, 13, 52, 77, 53, 70, 73))
```
```{r}
a1 <- c(1, -1, 5, -12, -12, 3, 8, -10, 0)
a2 <- c(76, 65, 71, 16, 60, 29, 71, 46, 45, 41)
a3 <- c(-2, 16, -3, 16, -9, 7, 31)
a4 <- c(-19, -9, 19, 5, -14, 0, 34, -8, 34, 24, -11, 8, 33, 12, -6)
a5 <- c(NA, NA, NA, NA, NA, NA, 3, NA, NA)
a6 <- c(-13, 19, -24, NA, 30, 64, -53, NA, 50, 31, -58, -34, -3, -34, 77)

mean(a1)
mean(a2)
mean(a3)
mean(a4)
mean(a5)
```

###median()

```{r}
b1 <- c(-92, -50, 54, 55, 84, 52, -55, -23, 36, -11, 22, 11, -7)
b2 <- c(1, 9, NA, 88, 2, NA, 42, NA, 4, 68, NA)
b3 <- c(-15, 71, 77, 36, 66, -21, -48, -8)
b4 <- c(19, 89, 78, 38, 8, 17, 25, 60, 8, 43, 29, 6, 62, 41, 69, 97, 61, 83, 25, 24)
b5 <- c(-91, -33, 13, 34, 34, 75, -80, -35, -90, -72, 70, 67, -100, -94, -18)

median(b1)
median(b2, na.rm = TRUE)
median(b3)
median(b4)
median(b5)
```

###min(), max()
```{r}
c1 <- c(68.92, 44.15, 34.2, 34.12, 37.7, 73.95, 36.9, 59.26, 31.06, 55.79, 73.92, 68.04, 53.73, 90.7, 39.66)
c2 <- c(90.48, 31.16, 44.4, 21.94, 84.37, 53.15, 81.15, 47.86, 63.23, 46.75, 102.73)
c3 <- c(48.11, 45.3, 58.42, 51.64, 62.07, 57.26, 49.69, 93.29, 81.18, 44.78, 55.1, 76.74, 58.08)
c4 <- c(17.24, 35.77, 57.57, 30.15, 43.27, 77.56, 72.19, 40.45, 46.2, 39.92)
c5 <- c(60.22, 31.91, 72.71, 52.49, 46.21, 60.39, 60.09)

min(c1, na.rm = FALSE)
max(c1, na.rm = FALSE)
min(c2, na.rm = FALSE)
max(c2, na.rm = FALSE)
min(c3, na.rm = FALSE)
max(c3, na.rm = FALSE)
min(c4, na.rm = FALSE)
max(c4, na.rm = FALSE)
min(c5, na.rm = FALSE)
max(c5, na.rm = FALSE)

```

###quantile()
```{r}
d1 <- c(80.94, 44.46, 46.33, 65.1, 66.42, 104.43, 53.15, 48.41, 12.88, 51.1, 43.03, 40.3, 33.71, 55.1, 22.17)
d2 <- c(26.17, 97.73, 24.81, 53.62, 87.72, 45.19, 45.7, 69.63, 36.76, 7.17)
d3 <- c(63.92, 35.85, 26.9, 48.92, 43.1, 66.94, 47.06, 56.54, 29.1, 58.88)
d4 <- c(32.05, 93.85, 85.52, 56.69, 23.69, 11.29, 51.44, 63.09, 65.65, 35.73, 60.15, 30.93, -4.2)

quantile(d1, probs = seq(0, 1, 0.25), na.rm = FALSE, names = TRUE, type = 7)
quantile(d2, probs = seq(0, 1, 0.25), na.rm = FALSE, names = TRUE, type = 7)
quantile(d3, probs = seq(0, 1, 0.025), na.rm = FALSE, names = TRUE, type = 7)
quantile(d4, probs = seq(0, 1, 0.25), na.rm = FALSE, names = TRUE, type = 7)
```

###var(), sd()

```{r}
e1 <- c(47.44, 62.44, 20.44, 72.75, 77.86, 13.74, 28.2, 50.47, 59.19, 69.04)
e2 <- c(49.31, 44.47, 14.04, 44.43, 49.18, 40.73, 44.65, 41.91, 80.38, 80.09)
e3 <- c(57.96, 20.81, 8.92, 14.03, 61.02, 25.69, 21.22, 49.56, 25.64, 28.31)
e4 <- c(76.22, 65, 19.69, 29.84, 37.18, 70.93, 64.78, 61.66, 49.03, 51.56)
e5 <- c(92.11, 56, 47.89, 62.96, 47.41, 37.05, 73.96, 53, 52.37, 85.23)

var(e1, na.rm = TRUE)
sd(e1, na.rm = TRUE)
var(e2, na.rm = TRUE)
sd(e2, na.rm = TRUE)
var(e3, na.rm = TRUE)
sd(e3, na.rm = TRUE)
var(e4, na.rm = TRUE)
sd(e4, na.rm = TRUE)
var(e5, na.rm = TRUE)
sd(e5, na.rm = TRUE)
```

###IQR()

```{r}
f1 <- c(80.94, 44.46, 46.33, 65.1, 66.42, 104.43, 53.15, 48.41, 12.88, 51.1, 43.03, 40.3, 33.71, 55.1, 22.17)
f2 <- c(26.17, 97.73, 24.81, 53.62, 87.72, 45.19, 45.7, 69.63, 36.76, 7.17)
f3 <- c(63.92, 35.85, 26.9, 48.92, 43.1, 66.94, 47.06, 56.54, 29.1, 58.88)
f4 <- c(32.05, 93.85, 85.52, 56.69, 23.69, 11.29, 51.44, 63.09, 65.65, 35.73, 60.15, 30.93, -4.2)

IQR(f1, na.rm = FALSE, type = 7)
IQR(f2, na.rm = FALSE, type = 7)
IQR(f3, na.rm = FALSE, type = 7)
IQR(f4, na.rm = FALSE, type = 7)

```

###length()

```{r}
#Приведём лайфхак, косвенно связанный с количеством значений вектора. 

#Зачастую в работе нам нужно включить в таблицы количество значений без пропущенных значений и количество именно пропущенных значений:

#sum(!is.na(vec)): количество значений без учёта пропущенных;
#sum(is.na(vec)): количество пропущенных значений.
```

###Стандартная ошибка среднего sd(x)/sqrt(length(x))

```{r}
d1 <- c(47.44, 62.44, 20.44, 72.75, 77.86, 13.74, 28.2, 50.47, 59.19, 69.04)
d2 <- c(49.31, 44.47, 14.04, 44.43, 49.18, 40.73, 44.65, 41.91, 80.38, 80.09)
d3 <- c(57.96, 20.81, 8.92, 14.03, 61.02, 25.69, 21.22, 49.56, 25.64, 28.31)
d4 <- c(76.22, 65, 19.69, 29.84, 37.18, 70.93, 64.78, 61.66, 49.03, 51.56)
d5 <- c(92.11, 56, 47.89, 62.96, 47.41, 37.05, 73.96, 53, 52.37, 85.23)

sd(d1)/sqrt(length(d1))
sd(d2)/sqrt(length(d2))
sd(d3)/sqrt(length(d3))
sd(d4)/sqrt(length(d4))
sd(d5)/sqrt(length(d5))

```

###summary()

###psych::describe()
```{r}
data <- read_rds("data/raw/numeric_data.rds")
describe(data, na.rm = TRUE, skew = FALSE, ranges = TRUE)
```

#table(), prop.table()

```{r}
data1 <- read_rds("data/raw/factor_data.rds")
table(data1$Группа, data1$`Группа крови`)
```


