---
title: "home_work"
subtitle: "DEAD|LINE"
author: "Zarva_I"
date: "2024-09-17"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---
##START
```{r setup, include=FALSE, error = TRUE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages(c("bayesplot", "bayestestR")) #установил пакет через команду)
library(tidyverse)
library(flextable)
library(DescTools)
library(psych)
library(ggcorrplot)
library(ggpubr)
library(readxl)
library(readr)
library(tibble)

```
## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

##Domashka

citation("ggplot2")
.libPaths()
library()
source("https://bioconductor.org/biocLite.R")

###Bioconductor
```{r}
if (!require("BiocManager", quietly = TRUE))  #установил Bioconductor
  install.packages("BiocManager")

BiocManager::install("BiocVersion")
```

###dplyr
```{r}
#mutate() — изменяет переменные, добавляет новые;
#select() — выбирает переменные;
#filter() — фильтрует объекты по условиям;
#summarise() — вычисляет сводные статистики;
#arrange() — сортирует по переменным;
#group_by() — группирует по значениям переменных;
#*_join() — группа глаголов для склеивания двух таблиц по ключу.

#Пакет позволяет:
#Поворачивать данные, то есть, преобразовывать их в длинный и широкий форматы: #pivot_longer(), pivot_wider();
#Разворачивать данные из вложенных списков в простые таблицы: unnest_longer(), unnest_wider();
#Наоборот, делать из таблиц вложенные переменные: nest(), unnest();
#Разделять и объединять столбцы по разделителю строк: separate(), unite();
#Заполнять отсутствующие значения определёнными значениями или удалять их: complete(), drop_na(), fill(), replace_na().
```

###readr, readxl, haven
```{r}
#Три основных пакета, которые помогают читать данные.

#readr предназначен для чтения самых распространённых форматов данных: *.csv, *.txt, *.tsv;
#redxl помогает читать файлы *.xlsx или, иными словами, всё, что пересылается в формате Excel;
#haven читает форматы *.sas7bdat, *.sap, *.dta, *.sav, *.por, то есть данные из SAS.
```

###purrr
```{r}
#Этот пакет может поначалу казаться сложным для понимания, однако на самом деле он просто расширяет функционал уже известного семейства функций *apply().
#Функция map() и её расширения позволяют итерироваться по элементам векторов или списков самыми разными способами
```

###tibble
```{r}
#В базовом R уже есть data.frame, однако tibble позволяет создавать гораздо более приятные для работы таблицы данных.

#В отличие от data.frame он не приводит строки к факторам автоматически. Это нужно сделать самостоятельно, однако таким образом мы всегда в точности знаем, что находится в каждой переменной датафрейма;
#Имена переменных остаются такими же, какими были. Например, в переменной с названием "variable name" пробел не будет заменён на точку, вместо этого имя будет окружено апострофами (обычно находятся на букве "ё"), что сохраняет ожидания от названий;
#tibble оценивает переменные лениво. По существу, это значит, что при создании мы можем объявлять одну переменную на основе другой (но эта другая должна быть указана первой).
```

###ggplot2 и ggpubr
```{r}
#Для визуализации данных существует сразу два пакета: базовый ggplot, содержащий в себе почти всю необходимую для создания графики функциональность.
#Дополнительные интересные особенности вроде автоматического расчёта и добавления на график p-value, реализованы в пакете ggpubr.
```

###flextable
```{r}
#Необходимо ещё и напечатать эти таблицы в виде, пригодном для восприятия коллегами без лишних проблем. Именно для этого нужен пакет flextable
```

###stringr
```{r}
#Очень часто в данных есть строковые переменные, в которых записана некая текстовая информация, важная нам для исследования. Например, в одной ячейке записаны все возможные названия препарата, и стоит задача взять только тех участников исследования, у которых название препарата содержит подстроку "циклин".
```

###lubridate
```{r}
#Помимо строковых данных часто встречаются и даты. С ними нельзя работать как с факторами, строками или, тем более, числами. Для этого существует специальная библиотека, которая может даже вычислить разницу между двумя датами с учётом високосных годов. 
```

###DescTools, psych
```{r}
#Существуют пакеты, в которых собраны статистические функции, позволяющие чуть ли не в одну строку подготовить базовый статистический отчёт.
#В DescTools мы найдём полезные функции для статистических тестов и доверительных интервалов, а в psych функции для корреляционных матриц и расчёта сразу группы статистик.
```

###read.*
```{r}
#Выше мы видим пример файла csv с разделителем-запятой. Обсудим конкретно, какими функциями читается каждый формат:

#read.csv() читает csv с запятой в качестве разделителя;
#read.csv2() читает csv с точкой с запятой в качестве разделителя (кстати, этот же формат отлично читает Excel, сразу разбивая его на столбцы);
#read.tsv() читает csv со знаком табуляции в качестве разделителя (часто этот формат сохраняют в файле с расширением .txt).
#Однако, в каждой функции при этом можно указать параметры sep, quote, dec, которые, соответственно, устанавливают знаки: разделителя, кавычек, десятичного разделителя. 
```

###write.*
```{r}
#write.csv(), write.csv2() печатают датафрейм в файлы csv с соответствующими разделителями, но их использование (особенно на Windows) может приводить к забавной вещи — поломке кодировки, когда символы в Excel не читаются человеком. Как решить эту проблему, мы узнаем в следующих шагах.
```

```{r}
read_tsv("data/raw/data_tsv.tsv", skip = 0, n_max = 10, col_names = TRUE)
```

###iris
```{r}
library(datasets)
data(iris)
summary(iris)
```
```{r}

#write_csv(data, "data/raw/data_csv.csv")

#write_excel_csv(data, "data/raw/data_csv.csv")

#write_csv2(data, "data/raw/data_csv2.csv")

#write_excel_csv2(data, "data/raw/data_csv2.csv")

#Ничего не работает...
```

###read_excel
```{r}
data <- read_excel("data/raw/data_excel.xlsx", sheet = "data_csv2")
head(data)
```

###xlsx::write.xlsx()

```{r}
#Существует несколько пакетов, позволяющих записывать данные в книги Excel: xlsx, openxlsx, writexl. Однако, здесь мы будем использовать openxlsx, поскольку он не требует установки Java и наиболее просто устанавливается почти на всех компьютерах.

#write.xlsx(data, "data_excel.xlsx", colNames = TRUE)

#Вот и всё. У нас появляется файл Excel с записанными данными. Перейдём к бонусу для тех, у кого установлен Java.

#openxlsx::write.xlsx(), openxlsx::write.xlsx2()

#Прежде всего отметим, что дублирующая функция с цифрой 2 используется преимущественно для того, чтобы быстро записывать крайне большие датафреймы (более, чем 100 тысяч ячеек).

#write.xlsx(data, "data_excel.xlsx", sheetName = "data", col.names = TRUE, row.names = TRUE, append = FALSE)

#Функция создаёт книгу Excel, а в ней лист с соответствующим именем. Аргументы col.names и row.names говорят, нужно ли записывать в файл имена столбцов и имена строк соответственно. Аргумент append нужен для того, чтобы...

#write.xlsx(data, "data_excel.xlsx", sheetName = "data_2", col.names = TRUE, row.names = TRUE, append = TRUE)

#...добавлять новые листы к уже существующей книге. 

#haven::read_spss(), haven::read_sas()

#Очень редко, но приходится читать данные, которые выгружены напрямую из SPSS или SAS.

#haven::write_sav() 

#Точно так же можно записать данные, чтобы наш предполагаемый коллега мог загрузить их в SPSS.

```


###mean()
```{r}
mean(c(20, 68, 45, 76, 41, 36, 13, 52, 77, 53, 70, 73))
```
```{r}
a1 <- c(1, -1, 5, -12, -12, 3, 8, -10, 0)
a2 <- c(76, 65, 71, 16, 60, 29, 71, 46, 45, 41)
a3 <- c(-2, 16, -3, 16, -9, 7, 31)
a4 <- c(-19, -9, 19, 5, -14, 0, 34, -8, 34, 24, -11, 8, 33, 12, -6)
a5 <- c(NA, NA, NA, NA, NA, NA, 3, NA, NA)
a6 <- c(-13, 19, -24, NA, 30, 64, -53, NA, 50, 31, -58, -34, -3, -34, 77)

mean(a1)
mean(a2)
mean(a3)
mean(a4)
mean(a5)
```

###median()

```{r}
b1 <- c(-92, -50, 54, 55, 84, 52, -55, -23, 36, -11, 22, 11, -7)
b2 <- c(1, 9, NA, 88, 2, NA, 42, NA, 4, 68, NA)
b3 <- c(-15, 71, 77, 36, 66, -21, -48, -8)
b4 <- c(19, 89, 78, 38, 8, 17, 25, 60, 8, 43, 29, 6, 62, 41, 69, 97, 61, 83, 25, 24)
b5 <- c(-91, -33, 13, 34, 34, 75, -80, -35, -90, -72, 70, 67, -100, -94, -18)

median(b1)
median(b2, na.rm = TRUE)
median(b3)
median(b4)
median(b5)
```

###min(), max()
```{r}
c1 <- c(68.92, 44.15, 34.2, 34.12, 37.7, 73.95, 36.9, 59.26, 31.06, 55.79, 73.92, 68.04, 53.73, 90.7, 39.66)
c2 <- c(90.48, 31.16, 44.4, 21.94, 84.37, 53.15, 81.15, 47.86, 63.23, 46.75, 102.73)
c3 <- c(48.11, 45.3, 58.42, 51.64, 62.07, 57.26, 49.69, 93.29, 81.18, 44.78, 55.1, 76.74, 58.08)
c4 <- c(17.24, 35.77, 57.57, 30.15, 43.27, 77.56, 72.19, 40.45, 46.2, 39.92)
c5 <- c(60.22, 31.91, 72.71, 52.49, 46.21, 60.39, 60.09)

min(c1, na.rm = FALSE)
max(c1, na.rm = FALSE)
min(c2, na.rm = FALSE)
max(c2, na.rm = FALSE)
min(c3, na.rm = FALSE)
max(c3, na.rm = FALSE)
min(c4, na.rm = FALSE)
max(c4, na.rm = FALSE)
min(c5, na.rm = FALSE)
max(c5, na.rm = FALSE)

```

###quantile()
```{r}
d1 <- c(80.94, 44.46, 46.33, 65.1, 66.42, 104.43, 53.15, 48.41, 12.88, 51.1, 43.03, 40.3, 33.71, 55.1, 22.17)
d2 <- c(26.17, 97.73, 24.81, 53.62, 87.72, 45.19, 45.7, 69.63, 36.76, 7.17)
d3 <- c(63.92, 35.85, 26.9, 48.92, 43.1, 66.94, 47.06, 56.54, 29.1, 58.88)
d4 <- c(32.05, 93.85, 85.52, 56.69, 23.69, 11.29, 51.44, 63.09, 65.65, 35.73, 60.15, 30.93, -4.2)

quantile(d1, probs = seq(0, 1, 0.25), na.rm = FALSE, names = TRUE, type = 7)
quantile(d2, probs = seq(0, 1, 0.25), na.rm = FALSE, names = TRUE, type = 7)
quantile(d3, probs = seq(0, 1, 0.025), na.rm = FALSE, names = TRUE, type = 7)
quantile(d4, probs = seq(0, 1, 0.25), na.rm = FALSE, names = TRUE, type = 7)
```

###var(), sd()

```{r}
e1 <- c(47.44, 62.44, 20.44, 72.75, 77.86, 13.74, 28.2, 50.47, 59.19, 69.04)
e2 <- c(49.31, 44.47, 14.04, 44.43, 49.18, 40.73, 44.65, 41.91, 80.38, 80.09)
e3 <- c(57.96, 20.81, 8.92, 14.03, 61.02, 25.69, 21.22, 49.56, 25.64, 28.31)
e4 <- c(76.22, 65, 19.69, 29.84, 37.18, 70.93, 64.78, 61.66, 49.03, 51.56)
e5 <- c(92.11, 56, 47.89, 62.96, 47.41, 37.05, 73.96, 53, 52.37, 85.23)

var(e1, na.rm = TRUE)
sd(e1, na.rm = TRUE)
var(e2, na.rm = TRUE)
sd(e2, na.rm = TRUE)
var(e3, na.rm = TRUE)
sd(e3, na.rm = TRUE)
var(e4, na.rm = TRUE)
sd(e4, na.rm = TRUE)
var(e5, na.rm = TRUE)
sd(e5, na.rm = TRUE)
```

###IQR()

```{r}
f1 <- c(80.94, 44.46, 46.33, 65.1, 66.42, 104.43, 53.15, 48.41, 12.88, 51.1, 43.03, 40.3, 33.71, 55.1, 22.17)
f2 <- c(26.17, 97.73, 24.81, 53.62, 87.72, 45.19, 45.7, 69.63, 36.76, 7.17)
f3 <- c(63.92, 35.85, 26.9, 48.92, 43.1, 66.94, 47.06, 56.54, 29.1, 58.88)
f4 <- c(32.05, 93.85, 85.52, 56.69, 23.69, 11.29, 51.44, 63.09, 65.65, 35.73, 60.15, 30.93, -4.2)

IQR(f1, na.rm = FALSE, type = 7)
IQR(f2, na.rm = FALSE, type = 7)
IQR(f3, na.rm = FALSE, type = 7)
IQR(f4, na.rm = FALSE, type = 7)

```

###length()

```{r}
#Приведём лайфхак, косвенно связанный с количеством значений вектора. 

#Зачастую в работе нам нужно включить в таблицы количество значений без пропущенных значений и количество именно пропущенных значений:

#sum(!is.na(vec)): количество значений без учёта пропущенных;
#sum(is.na(vec)): количество пропущенных значений.
```

###Стандартная ошибка среднего sd(x)/sqrt(length(x))

```{r}
d1 <- c(47.44, 62.44, 20.44, 72.75, 77.86, 13.74, 28.2, 50.47, 59.19, 69.04)
d2 <- c(49.31, 44.47, 14.04, 44.43, 49.18, 40.73, 44.65, 41.91, 80.38, 80.09)
d3 <- c(57.96, 20.81, 8.92, 14.03, 61.02, 25.69, 21.22, 49.56, 25.64, 28.31)
d4 <- c(76.22, 65, 19.69, 29.84, 37.18, 70.93, 64.78, 61.66, 49.03, 51.56)
d5 <- c(92.11, 56, 47.89, 62.96, 47.41, 37.05, 73.96, 53, 52.37, 85.23)

sd(d1)/sqrt(length(d1))
sd(d2)/sqrt(length(d2))
sd(d3)/sqrt(length(d3))
sd(d4)/sqrt(length(d4))
sd(d5)/sqrt(length(d5))

```

###summary()

###psych::describe()
```{r}
data <- read_rds("data/raw/numeric_data.rds")
describe(data, na.rm = TRUE, skew = FALSE, ranges = TRUE)
summary(data)
```

###table(), prop.table()

```{r}
FData <- read_rds("data/raw/factor_data.rds")
table(data1$Группа, data1$`Группа крови`)
```

###tibble()
```{r}
#Особенности tibble:

#tibble не изменяют тип ввода. Если вы вводили переменные типа character, то такими они и будут. Если numeric, то будут numeric. В том числе это позволяет даже вводить в качестве значений ячеек списки!
#tibble не меняет имена переменных: если вы ввели имя с пробелом, то он не будет заполнен точкой или иным знаком, однако, нужно оборачивать имена в апострофы (чаще всего находится на клавише буквы "ё" в верхнем левом углу клавиатуры). Это следует делать всякий раз, когда имя переменной отличается от простой строки на латинице без иных знаков. Например: columnname не требует апострофов, а `column name` уже требует;
#Оценивает аргументы лениво и последовательно, что мы разберём в следующем шаге;
#Не использует имена строк;
#При выводе таблицы данных в печать автоматически будут показаны только первые 10 строк и все столбцы, которые поместятся на экран. Благодаря этому даже очень большой датафрейм не заставит наш компьютер зависнуть.
#Заметка: чтобы превратить data.frame в tibble, достаточно просто применить функцию as_tibble()
```

tibble(var_first = 1:10, var_second = ifelse(var_first < 5, var_first + 100, var_first))
tibble(var = 1:10, var = var - 10000000)
tibble(`var 1` = 1:10, `var 2` = `var 1` * 100)
tibble(var_first = 1:10, var_first = ifelse(var_first < 5, var_first + 100, var_first))
tibble(`var 2` = 10:1, `var 3` = `var 1` - 10)
tibble(var_1 = c(1:10) - 100, var_2 = 1:100)

###View()
###tibble::add_column()
```{r}
#data %>% add_column(column_name = 1:10, .before = NULL, .after = NULL)

#data: просто имя датафрейма, к которому мы хотим добавить столбец;
#column_name: это имя нового столбца. Оно может быть любым, не только таким, как в примере;
#.before: номер уже существующего столбца, перед которым нужно поставить новый;
#.after: то же, но уже после которого нужно поставить новый. Хитрый приём: если нужно поставить переменную в конец датафрейма, то в значение можно поставить Inf.
```

###tibble::add_row()
```{r}
#data %>% add_row(var_1 = 1, var_2 = "value", .before = NULL, .after = NULL)

#data: просто имя датафрейма, к которому мы хотим добавить столбец;
#var_1, var_2: это имя нового столбца. Оно может быть любым, не только таким, как в примере;
#.before: номер уже существующей строки, перед которым нужно поставить новый;
#.after: то же, но уже после которого нужно поставить новый. Хитрый приём: если нужно поставить переменную в низ датафрейма, то в значение можно поставить Inf
```

###dplyr::row_number()

###dplyr::bind_cols()
```{r}
#Мы можем сделать из двух и более таблиц одну, склеив их столбцы.

#data_1 %>% bind_cols(data_2) %>% bind_cols(data_3)
```

###dplyr::bind_rows()
```{r}
#То же самое можно сделать и для склеивания строк. Один датафрейм под другим.

#data_1 %>% bind_rows(data_2) %>% bind_rows(data_3)
```

###dplyr::left_join(), dplyr::right_join(), dplyr::inner_join(), dplyr::full_join()

```{r}
#Есть четыре функции, которые позволяют склеивать датафреймы по ключевым переменным (только два, назовём их x и y):
#left_join(x, y): включает все строки, которые есть в x, отбрасывая из y те, которых нет;
#right_join(x, y): включает все строки, которые есть в y, отбрасывая те, которых там нет;
#inner_join(x, y): включает все строки, которые есть и в x и y;
#full_join(x, y): просто включает все строки, которые есть хотя бы в x или y.
#Каждый датафрейм должен иметь одну (или более) важных переменных: ключевых переменных.
#Этот концепт очень прост. Должна быть уникальная переменная, например, ID пациента, по которой функция понимает, какую строку с какой сопоставлять. Это может быть не только одна переменная, но и их уникальное сочетание, например, ID пациента, его визиты, а также получаемый препарат. Эти три переменных и являются в таком случае уникальным ключом к сопоставлению строк.
#Почти всегда мы будем использовать именно left_join(), но разберём примеры работы всех функций, чтобы знать, чего ожидать.
#data_1 <- tibble(var_1 = 1:8) %>% mutate(id = row_number())
#data_2 <- tibble(var_2 = rnorm(10)) %>% mutate(`Subject ID` = row_number())
```

###dplyr::group_by()
```{r}
#Данные могут быть разделены на группы, которые стоит анализировать отдельно. В будущих шагах мы ещё изучим, как именно создавать группированные статистические таблицы.
#data %>% group_by(column_name)
#data %>% group_by(column_name) %>% ungroup()
```

###base::split()

###dplyr::rowwise()
```{r}
#mutate() будет изучена далее, однако уже сейчас мы можем понять, что происходит. С помощью rowwise() мы переключаем работу с датафреймом в режим работы по строкам. Далее вычисляем средние значения по строкам по двум переменными... выбираем эти две переменные и результирующую ради наглядности.
#Кстати. Обратите внимание, что ungroup() работает и для rowwise(). Лучше всегда разгруппировывать датафрейм после его группировки ради того, чтобы избежать неожиданных моментов.
```

###dplyr::select(), where()

```{r}
data %>%
  select('Группа крови','Рост')
```

```{r}
data %>%
  select(!'Группа крови')
```

```{r}
data %>%
  select(where(is.numeric))
```

data %>% select(function(x) sd(x, na.rm = TRUE) > 1)

data %>% select(`Группа`, function(x) !is.factor(x))

data %>% select(`Группа`, (function(x) is.factor(x)) | where(function(x) is.numeric(x)))

data %>% select(function(x) any(str_detect(x, "Жен")))

data %>% select(`Пол`, `Группа`, `Базофилы_E1`)

data %>% select(`Группа крови`, `Возраст`, function(x) anyNA(x))

data %>% select(where(is.numeric) & where(function(x) sd(x, na.rm = TRUE) > 1))

data %>% select(Группа крови, `Возраст`, function(x) anyNA(x))




data %>% mutate(across(!contains("E1") & !c(`Группа`, `Возраст`), function(x) x ^ 2))

data %>% mutate(across(!contains("E1"), function(x) str_c(x, " + некая строка")))

data %>% mutate(across(!contains("E1") & !c(`Группа`, `Возраст`) & !where(is.factor), function(x) x ^ 2), across(contains("E2"), function(x) x * 100))

data %>% mutate(across(function(x) any(near(x, 0.5, tol = 0.1)), function(x) x + 1000))

